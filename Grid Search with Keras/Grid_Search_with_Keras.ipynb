{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxX3u6ceh0sO"
   },
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://www.linkedin.com/company/mt-learners/\" target=\"_blank\">\n",
    "    <img src=\"https://github.com/Mr-MeerMoazzam/Mr-MeerMoazzam/blob/main/Untitled-2.jpg?raw=true\" width=\"200\" alt=\"MT Learners Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0ZHaG2Ih0sV"
   },
   "source": [
    "# **Master Hyperparameter Optimization with Scikit-Learn**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcVsEFFyh0sW"
   },
   "source": [
    "We are already familiar with using `RandomizedSearchCV` and `GridSearchCV` for hyperparameter tuning in machine learning models like linear regression and decision trees. However, we can also apply the same approach to neural networks effortlessly. Keras provides a scikit-learn wrapper that allows us to perform randomized and grid search on its models using a similar syntax, such as `fit()` and `.best_score_`. In this tutorial, we will explore how to use these techniques specifically for a Sequential model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awA6FhFch0sX",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"https://#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"https://#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"https://#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"https://#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"https://#Create-the-Model\">Create the Model</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Load-the-Data\">Load the Data</a></li>\n",
    "            <li><a href=\"https://#Data-Wrangling\">Data Wrangling</a></li>\n",
    "            <li><a href=\"https://#Build-the-Base-Model\">Build the Base Model</a></li>\n",
    "        </ol>\n",
    "    </li>  \n",
    "    <li>\n",
    "        <a href=\"https://#Randomized-Search\">Randomized Search</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Parameters\">Parameters</a></li>\n",
    "            <li><a href=\"https://#Define-and-Fit-RandomizedSearchCV\">Define and Fit RandomizedSearchCV</a></li>\n",
    "            <li><a href=\"https://#Performance-Evaluation\">Performance Evaluation</a></li>\n",
    "        </ol>\n",
    "    </li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDt9fHtDh0sa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "By the end of this tutorial, you will have the following skills:\n",
    "\n",
    "\n",
    "* Utilize Keras' scikit-learn wrapper to apply sklearn functions on Keras models\n",
    "\n",
    "* Employ randomized search on Keras models to identify the optimal hyperparameters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx2RwIDwh0sb"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imHkw4uKh0sc"
   },
   "source": [
    "In this tutorial, we will be using the following libraries:\n",
    "\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n",
    "*   [`tensorflow`](https://www.tensorflow.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and neural network related functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tl_wCI7rh0sd"
   },
   "source": [
    "### Installing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHQHq791h0sf",
    "outputId": "aa718534-e793-48aa-c9a2-799072376b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib scikit-learn tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M91Xmc99h0sj"
   },
   "source": [
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b2r9_MDCh0sj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMIfGW6xh0sk"
   },
   "source": [
    "### Defining Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UKR8N1fIh0sk"
   },
   "outputs": [],
   "source": [
    "# Vectorize integer sequence\n",
    "def vectorize_sequence(sequence, dimensions):\n",
    "    results = np.zeros((len(sequence), dimensions))\n",
    "    for index,value in enumerate(sequence):\n",
    "        if max(value) < dimensions:\n",
    "            results[index, value] = 1\n",
    "    return results\n",
    "\n",
    "# Convert label into one-hot format\n",
    "def one_hot_label(labels, dimensions):\n",
    "    results = np.zeros((len(labels), dimensions))\n",
    "    for index,value in enumerate(labels):\n",
    "        if value < dimensions:\n",
    "            results[index, value] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mF3VoLoYh0sl",
    "tags": []
   },
   "source": [
    "## Create the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tCEMm63h0sl"
   },
   "source": [
    "### Load the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGdxxzuHh0sm"
   },
   "source": [
    "In this tutorial, we will be working with the [Reuters newswire classification dataset](https://keras.io/api/datasets/reuters/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera35714171-2022-01-01) provided by Keras. The training features of this dataset consist of lists of word indices, each representing the frequency of occurrence within the dataset. The response labels, on the other hand, encompass a diverse range of 46 classes, reflecting the various captivating topics covered by the newswires. \n",
    "from Keras. The training features for this dataset are lists of word indices (integers), corresponding to their frequency in the dataset. The response labels take on one of 46 classes, representing the newswire's topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7ITFQ9YLh0sm"
   },
   "outputs": [],
   "source": [
    "X = np.load(\"/content/x.npy\", allow_pickle=True)\n",
    "y = np.load (\"/content/y.npy\", allow_pickle=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnrsWQ8qh0sm"
   },
   "source": [
    "To get the word for a specific index, we can also extract a dictionary of words to index using the following Keras function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DC7toIj9h0sn"
   },
   "outputs": [],
   "source": [
    "word_to_ind = tf.keras.datasets.reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgB0AcnYh0sn"
   },
   "source": [
    "### Data Wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ufa5M4_h0so"
   },
   "source": [
    "Since each observation is a list of words that appear in the newswire, the length varies. Hence, we will vectorize the dataset using `vectorize_sequence()` to ensure that all inputs to our model have the same dimension. Labels are also one-hot encoded with `one_hot_label()` because classes (news topic) are not ordinal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZGBQeFA5h0sp"
   },
   "outputs": [],
   "source": [
    "dim_x = max([max(sequence) for sequence in X_train])+1\n",
    "dim_y = max(y_train)+1\n",
    "\n",
    "X_train_vec = vectorize_sequence(X_train, dim_x)\n",
    "X_test_vec = vectorize_sequence(X_test, dim_x)\n",
    "y_train_hot = one_hot_label(y_train, dim_y)\n",
    "y_test_hot = one_hot_label(y_test, dim_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G1aUzVUh0sp"
   },
   "source": [
    "### Build the Base Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8CaRyTYh0sp"
   },
   "source": [
    "In order to apply `RandomizedSearchCV` on Keras models, we will be using `KerasClassifier` from `keras.wrappers.scikit_learn` library, which will let us apply scikit-learn functions on the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DP2ftuCih0sq"
   },
   "source": [
    "We define `create_model()` below to detail which layers we want to include in the model. Recall that the final Dense layer has 46 units to correspond to the number of classes. This also prompts us to use categorical cross entropy as a loss function. Here, `neuron` is included as a parameter with default value because we want to tune it later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9D48U2wnh0sq"
   },
   "outputs": [],
   "source": [
    "# Create Keras Sequential Model as base model\n",
    "def create_model(neurons = 10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='linear'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFGo3SQIh0sq"
   },
   "source": [
    "For the base model, we won't change any parameters so that we can compare them with results after hyperparameter tuning. We also specify some of the default values for hyperparameters that don't appear in `create_model()` (example batch_size, epochs) such that they are defined when applying randomized search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmSaH0ouh0sr",
    "outputId": "47863f0c-6d09-4d80-dd2d-b17be3630c12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-30534e014f32>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  base_model = KerasClassifier(build_fn=create_model, verbose=0, batch_size=10, epochs=1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "base_model = KerasClassifier(build_fn=create_model, verbose=0, batch_size=10, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMNeiZbah0ss"
   },
   "source": [
    "Fitting the model on the train set, we obtain the test score for our base model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_I9dkgdh0st",
    "outputId": "57c752dc-37a6-4e6a-dfbb-35ce9b988d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline accuracy is: 0.734\n"
     ]
    }
   ],
   "source": [
    "# Get pre-tuned results\n",
    "base_model.fit(X_train_vec, y_train_hot)\n",
    "base_score = base_model.score(X_test_vec, y_test_hot)\n",
    "print(\"The baseline accuracy is: %.3f\" % base_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsJLJ33wh0su"
   },
   "source": [
    "## Randomized Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtuY2BNBh0su"
   },
   "source": [
    "### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIAqhRHxh0sv"
   },
   "source": [
    "\n",
    "As you may be familiar with from your previous encounters with randomized search on machine learning models, it is necessary to create a dictionary specifying the hyperparameter values for experimentation. To begin, let's define the values we intend to explore. It is important to note that if you wish to test additional parameters, they must also be defined in the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wk96bGwAh0sv",
    "outputId": "f3c3980a-ae70-44f6-b66d-34247aabe6ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [10, 30, 50, 70],\n",
       " 'epochs': [1, 5, 7],\n",
       " 'neurons': [1, 10, 40, 50]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = [10, 30, 50, 70]\n",
    "epochs = [1, 5, 7]\n",
    "neurons = [1, 10, 40, 50]\n",
    "\n",
    "params = dict(batch_size=batch_size, epochs=epochs, neurons=neurons)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlYNmmMch0sw"
   },
   "source": [
    "### Define and Fit RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "q_RizHWXh0sw"
   },
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(estimator=base_model, param_distributions=params, cv=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDYo3naGh0sw"
   },
   "source": [
    "Now, fit randomized search on `X_train_vec` and `y_train_hot` as you would for any other model. **Note that this may take a while to run (10+ minutes)**, especially if there are a lot of parameter combinations, or if the epoch size is big. If you have the resources, you could also switch out `RandomizedSearchCV` for `GridSearchCV` to search over every combination of hyperparameters (takes even more time to run).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdKG5w_Jh0sx"
   },
   "outputs": [],
   "source": [
    "search_result = search.fit(X_train_vec, y_train_hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYufWOMGh0sx"
   },
   "source": [
    "### Performance Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQIPI0oTh0s7"
   },
   "source": [
    "Let's take a look at the results from this search! In particular, we will examine the mean and standard deviation of the cross-validation score under different hyperparameter combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-W1uEzMh0s7"
   },
   "outputs": [],
   "source": [
    "means = search_result.cv_results_['mean_test_score']\n",
    "stds = search_result.cv_results_['std_test_score']\n",
    "params = search_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evY4UtyLh0s8"
   },
   "source": [
    "`RandomizedSearchCV` also has attributes for us to access the best score and parameters directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0gqXVs5h0s9"
   },
   "outputs": [],
   "source": [
    "print(\"Best mean cross-validated score: {} using {}\".format(round(search_result.best_score_,3), search_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPQSHdpZh0s9"
   },
   "source": [
    "We can also print out all the other scores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9VbhaGjh0s9"
   },
   "outputs": [],
   "source": [
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean cross-validated score: {} ({}) using: {}\".format(round(mean,3), round(stdev,3), param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1F17rFqBh0s-"
   },
   "source": [
    "From this, we can see how different the other models' scores are compared to the optimal model's performance. Some are pretty close to the best score, whereas there are combinations that yield much lower scores.Thank goodness we didn't pick those! With randomized search on neural networks, we are able to determine the best values in an automated way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peMYAz8dh0s-"
   },
   "source": [
    "Using the best estimator, let's get the test score:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUSxJ0aFh0s-"
   },
   "outputs": [],
   "source": [
    "print(\"Best test score: %.3f\" % search_result.best_estimator_.score(X_test_vec, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaNJ45y-h0s_"
   },
   "source": [
    "Our test score has increased compared to the base model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moxxL8NDh0tF"
   },
   "source": [
    "## Author\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU7m8Czch0tF"
   },
   "source": [
    "[Moazzam Ali](https://www.linkedin.com/in/moazzam-ali-6a9675237/) is a Machine Learning Engineer at TokToAI."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
